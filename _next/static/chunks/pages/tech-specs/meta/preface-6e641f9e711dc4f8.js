(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[3912],{1988:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/tech-specs/meta/preface",function(){return n(5322)}])},5322:function(e,t,n){"use strict";n.r(t),n.d(t,{__toc:function(){return d}});var i=n(5893),a=n(2673),r=n(2169),o=n(2069);n(9488);var c=n(2643),s=n(8757),l=n(2154);let d=[{depth:2,value:"A.I. Chatbot",id:"ai-chatbot"},{depth:2,value:"Migration Schema",id:"migration-schema"},{depth:2,value:"LLM Schema",id:"llm-schema"},{depth:2,value:"WebSocket RPC",id:"websocket-rpc"},{depth:2,value:"Function Call Execution",id:"function-call-execution"}];function p(e){let t=Object.assign({h2:"h2",p:"p",a:"a",strong:"strong",ul:"ul",li:"li",code:"code",ol:"ol"},(0,c.a)(),e.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h2,{id:"ai-chatbot",children:"A.I. Chatbot"}),"\n",(0,i.jsx)(s.G,{chart:'flowchart\n  subgraph "OpenAPI Specification"\n    v20(Swagger v2.0) --upgrades--> emended[["OpenAPI v3.1 (emended)"]]\n    v30(OpenAPI v3.0) --upgrades--> emended\n    v31(OpenAPI v3.1) --emends--> emended\n  end\n  subgraph "Ecosystem"\n    emended --normalizes--> migration[["Migration Schema"]]\n    migration --downgrades--> lfc{{"LLM Function Calling Schema"}}\n    migration --metadata--> compiler{{"Workflow Compiler"}}\n    emended --sales--> marketplace{{"API Marketplace"}}\n  end\n  subgraph "Artificial Intelligence"\n    lfc --executor--> meta[("<b><u>Meta LLM (A.I. Chatbot)</u></b>")]\n    compiler --provider--> meta\n    marketplace -.supplier.-> meta\n    meta --stroyline--> swl(["SWL Language"])\n    swl --compiles--> program[/"Re-usable Workflow Program"\\]\n    meta -.private.- prompt((("System Prompt")))\n    meta -.protocol.- websocket((("WebSocket RPC")))\n  end'}),"\n",(0,i.jsx)(t.p,{children:'"Wrtn Studio Pro" provides an A.I. chatbot service called "Meta LLM".'}),"\n",(0,i.jsxs)(t.p,{children:['The "Meta LLM" utilizes ',(0,i.jsx)(t.a,{href:"https://platform.openai.com/docs/guides/function-calling",children:"LLM (Large Language Model) function calling"}),", and the functions come from the ",(0,i.jsx)(t.a,{href:"/tech-specs/marketplace/preface",children:"API marketplace"})," sales which is following the ",(0,i.jsx)(t.a,{href:"/tech-specs/openapi/preface",children:"OpenAPI specification"}),'. Also, when user wants to automate his/her chatting scenario as an automated program, "Wrtn Studio Pro" builds it a program function through the ',(0,i.jsx)(t.a,{href:"/tech-specs/workflow/preface",children:"Workflow Compiler"})," with ",(0,i.jsx)(t.a,{href:"/tech-specs/swl/preface",children:"SWL language"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:['By the way, LLM function calling schema appears similar to the OpenAPI specification at first glance, but in reality the specifications are quite different. In such reason, "Wrtn Studio Pro" has a process of converting OpenAPI to ',(0,i.jsx)(t.a,{href:"/tech-specs/meta/schema",children:"LLM function calling schema"}),", and at this time, it goes through an intermediate conversion process called ",(0,i.jsx)(t.a,{href:"/tech-specs/meta/migrate",children:"Migration Schema"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:['Also, "Wrtn Studio Pro" has adopted WebSocket protocol when developing the A.I. chatbot service. If explain the WebSocket protocol related story more detaily, "Wrtn Studio Pro" has adopted the ',(0,i.jsx)(t.a,{href:"https://tgrid.com/docs/remote-procedure-call",children:"RPC (Remote Procedure Call)"})," paradigm. It is a structure in which the client and server participating in the chatbot remotely call the functions provided by each other."]}),"\n",(0,i.jsx)(t.p,{children:'At last, when performing function call execution in the "Meta LLM", "Wrtn Studio Pro" separates the parameter arguments composition to both Humand and LLM sides. It\'s because some arguments must be composed by Human like file uploading or secret key identification.'}),"\n",(0,i.jsxs)(l.UW,{type:"info",children:[(0,i.jsx)(t.p,{children:(0,i.jsx)(t.strong,{children:"LLM Function Calling"})}),(0,i.jsx)(t.p,{children:"LLM selects proper function and fill arguments."}),(0,i.jsx)(t.p,{children:'In nowadays, most LLM (Large Language Model) like OpenAI are supporting "function calling" feature. The "function calling" means that LLM automatically selects a proper function and compose parameter values from the user\'s chatting text.'}),(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://platform.openai.com/docs/guides/function-calling",children:"https://platform.openai.com/docs/guides/function-calling"})})]}),"\n",(0,i.jsx)(t.h2,{id:"migration-schema",children:"Migration Schema"}),"\n",(0,i.jsx)(s.G,{chart:'flowchart\n  v20(Swagger v2.0) --upgrades--> emended[["OpenAPI v3.1 (emended)"]]\n  v30(OpenAPI v3.0) --upgrades--> emended\n  v31(OpenAPI v3.1) --emends--> emended\n  emended --normalizes--> migration[["<b><u>Migration Schema</u></b>"]]\n  migration --downgrades--> lfc{{"LLM Function Calling Schema"}}\n  migration --metadata--> workflow{{"Workflow Compiler"}}'}),"\n",(0,i.jsx)(t.p,{children:"Intermediate structure for LLM function calling schema conversion."}),"\n",(0,i.jsx)(t.p,{children:'LLM function calling schema is different with OpenAPi specification. Therefore, "Wrtn Studio Pro" must convert the OpenAPI spefification to the LLM function calling schema. However, the conversion process is not direct, but through the intermediate structure called "Migration Schema".'}),"\n",(0,i.jsx)(t.p,{children:'Purpose of the Migration Schema is to normalize parameters and responses of the OpenAPI operation. By providing the normalized definitions close to the RPC (Remote Procedure Call) function, "Wrtn Studio Pro" can safely convert to the LLM function calling schema from the OpenAPI document.'}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://github.com/samchon/openapi/blob/master/src/IMigrateDocument.ts",children:(0,i.jsx)(t.code,{children:"IMigrateDocument"})})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://github.com/samchon/openapi/blob/master/src/IMigrateRoute.ts",children:(0,i.jsx)(t.code,{children:"IMigrateRoute"})})}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"llm-schema",children:"LLM Schema"}),"\n",(0,i.jsx)(s.G,{chart:"flowchart\nIOpenAiDocument --functions--- IOpenAiFunction\nIOpenAiFunction --references--- IMigrateRoute\nIOpenAiFunction --schema--- IOpenAiSchema"}),"\n",(0,i.jsx)(t.p,{children:'"Wrtn Studio Pro" has defined full specification of the LLM function calling schema.'}),"\n",(0,i.jsx)(t.p,{children:"It has been converted from the OpenAPI specification bypass the migration process. The OpenAI function calling schema forms a RPC (Remote Procedure Call) structure that can be directly executed by the Meta LLM."}),"\n",(0,i.jsx)(t.p,{children:"Its type schema information is similar with OpenAPI v3.0 specification, but reference type does not exist. Therefore, if there's a recursive referrence type exists in an OpenAPI operation, the operation cannot be converted to the LLM function calling schema."}),"\n",(0,i.jsxs)(t.p,{children:["Also, ",(0,i.jsx)(t.code,{children:"IOpenAiFunction"}),"'s parameters are separated to two parts; Human and LLM. The Human part is composed by the user's input, and the LLM part is composed by the Meta LLM's output. The reason of such separation is, some parameter values must be composed by Human like file uploading or secret key identification."]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://github.com/wrtnio/openai-function-schema/blob/main/src/structures/IOpenAiDocument.ts",children:(0,i.jsx)(t.code,{children:"IOpenAiDocument"})})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://github.com/wrtnio/openai-function-schema/blob/main/src/structures/IOpenAiFunction.ts",children:(0,i.jsx)(t.code,{children:"IOpenAiFunction"})})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://github.com/wrtnio/openai-function-schema/blob/main/src/structures/IOpenAiSchema.ts",children:(0,i.jsx)(t.code,{children:"IOpenAiSchema"})})}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"websocket-rpc",children:"WebSocket RPC"}),"\n",(0,i.jsx)(s.G,{chart:"sequenceDiagram\nbox Client Application\n  actor User\n  participant Driver as Driver<Listener>\n  participant Connector as Communicator (Client)\nend\nbox Server Application\n  participant Acceptor as Communicator (Server)\n  actor Provider\nend\nUser->>Driver: 1. calls a function\nActivate User\nActivate Driver\nDriver->>Connector: 2. delivers the function call\nActivate Connector\nDeactivate Driver\nConnector-->>Acceptor: 3. sends a protocolized<br/>network message<br/>meaning a function call\nDeactivate Connector\nActivate Acceptor\nAcceptor->>Provider: 4. calls the function\nProvider->>Acceptor: 5. returns a value\nAcceptor-->>Connector: 6. sends a protocolized<br/>network message<br/>meaning a return value\nDeactivate Acceptor\nActivate Connector\nConnector->>Driver: 7. delivers the return value\nDeactivate Connector\nActivate Driver\nDriver->>User: 8. returns the value\nDeactivate Driver\nDeactivate User"}),"\n",(0,i.jsx)(t.p,{children:"WebSocket protocol with RPC paradigm."}),"\n",(0,i.jsx)(t.p,{children:'"Wrnt Studio Pro" has adopted WebSocket protocol for the A.I. chatbot service. Also, accepting the WebSocket protocol, "Wrtn Studio Pro" is following the RPC (Remote Procedure Call) paradigm. By the RPC paradigm, the client and server participating in the A.I. chatbot are possible to remotely call the functions provided by each other.'}),"\n",(0,i.jsxs)(t.p,{children:["In the business logic level, the Meta LLM WebSocket server is providing ",(0,i.jsx)(t.code,{children:"IStudioMetaChatService"})," interface to the client, so that client can remotely call and get return values from the ",(0,i.jsx)(t.code,{children:"IStudioMetaChatService"})," instance composed by the server. Also, the client is providing ",(0,i.jsx)(t.code,{children:"IStudioMetaChatListener"})," instance and many LLM function call executions are performed with it."]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"https://tgrid.com/docs/remote-procedure-call/",children:"RPC (Remote Procedure Call)"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"/api/interfaces/structures_studio_meta_IStudioMetaChatService.IStudioMetaChatService-1.html",children:(0,i.jsx)(t.code,{children:"IStudioMetaChatService"})})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.a,{href:"/api/interfaces/structures_studio_meta_IStudioMetaChatListener.IStudioMetaChatListener-1.html",children:(0,i.jsx)(t.code,{children:"IStudioMetaChatListener"})})}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"function-call-execution",children:"Function Call Execution"}),"\n",(0,i.jsx)(s.G,{chart:'sequenceDiagram\n  box Client Application\n    actor Human\n    participant Listener\n  end\n  box Server Application\n    participant Service\n    actor LLM\n  end\n  Human->>Listener: 1. Start A.I. Chatbot\n  Listener-->>Service: 1.1. Call "Service.initialize()"\n  activate Service\n  Service->>LLM: 1.2. LLM function schemas<br/>from API marketplace\n  Service-->>Listener: 1.3. RPC returns session information\n  deactivate Service\n  Human->>Listener: 2. Typed chatting message<br/>"Send an email to my friend"\n  activate Human\n  Listener-->>Service: 2.1. Call "Service.talk()"\n  Service->>LLM: 2.2. Deliver the client message\n  activate LLM\n  LLM->>Service: 2.3. LLM analyzes the user text<br/>and predicated the message<br/>indicates the function call\n  Service-->>Listener: 2.4. Describe function call plan<br/>with detailed descriptions by calling<br/>"Service.explainFunctionCall()"\n  loop for each function\n    LLM->>Service: 3. Target a function to call\n    activate Service\n    Service->>Listener: 3.1. Deliver the target function<br/>metadata by calling<br/>"Service.selectFunction()"\n    LLM-->>Service: 3.2. Request to fill arguments<br/>of LLM side parameters<br/>by chatting text\n    Service-->>Listener: 3.3. Deliver the request of LLM<br/>to fill arguments of LLM side<br/>parameters with chatting text<br/>by calling "Listener.talk()"\n    Human->>Listener: 3.4. Type proper arguments by text\n    Listener-->>Service: 3.5. Call "Service.talk()"<br/>with chatting text<br/>indicating LLM side paramters\n    alt if Human side parameter exists\n      loop for each parameter composed by Human\n        Service-->>Listener: 3.6 Call "Service.fillArguments()"<br/>requesting client to fill<br/>the Human side parameter\n        activate Listener\n        Listener-->>Human: 3.6.1 Print inspector (UI component)\n        Human->>Listener: 3.6.3. Fill value with inspector\n        Listener-->>Service: 3.6.3. RPC returns the value\n        deactivate Listener\n      end\n    end\n    Service->>LLM: 3.7. Execute the function\n    Service-->>LLM: 3.7.1. Inform return value<br/>to LLM for the next step\n    deactivate LLM\n    Service-->>Listener: 3.7.2. Inform return value<br/>to the client by calling<br/>"Service.completeFunction()"\n    deactivate Service\n    Listener-->>Human: 3.7.3. Print return value viewer\n  end\n  deactivate Human'}),"\n",(0,i.jsx)(t.p,{children:"Function call execution process."}),"\n",(0,i.jsx)(t.p,{children:"The function call execution is processed by utilizing every skills listed up to now, including WebSocket protocol with RPC (Remote Procedure Call) paradigm and function call arguments filling by both Human and LLM (Large Language Model) sides."}),"\n",(0,i.jsx)(t.p,{children:"When the Meta LLM service has been started and it has delivered function calling schemas to the LLM (Large Language Model), the conversation with Human and LLM begins and LLM sometimes selects a function to call, and then the function call execution story begins."}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsx)(t.li,{children:"User talks something by chatting text."}),"\n",(0,i.jsx)(t.li,{children:"LLM analyzes the user text content."}),"\n",(0,i.jsx)(t.li,{children:"LLM selects a function, and server informs it to the client."}),"\n",(0,i.jsx)(t.li,{children:"LLM requests Human to type the arguments by chatting text"}),"\n",(0,i.jsx)(t.li,{children:"User fills the arguments by chatting text."}),"\n",(0,i.jsx)(t.li,{children:"Server requests clients to fill the Human side arguments."}),"\n",(0,i.jsx)(t.li,{children:"Human fills the arguments by UI component (inspector)."}),"\n",(0,i.jsx)(t.li,{children:"Server executes the function and informs the result."}),"\n"]})]})}let h={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:t}=Object.assign({},(0,c.a)(),e.components);return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(p,{...e})}):p(e)},pageOpts:{filePath:"pages/tech-specs/meta/preface.mdx",route:"/tech-specs/meta/preface",timestamp:1725274444e3,pageMap:[{kind:"Meta",data:{index:{title:"Project Outline",type:"page",hidden:!0,display:"hidden"},docs:{title:"\uD83D\uDCD6 Guide Documents",type:"page"},"tech-specs":{title:"\uD83D\uDEE0️ Technical Specifications",type:"page"}}},{kind:"Folder",name:"docs",route:"/docs",children:[{kind:"Meta",data:{index:"\uD83D\uDE4B\uD83C\uDFFB‍♂️ Introduction","-- features":{type:"separator",title:"\uD83D\uDCD6 Features"},membership:"Membership",meta:"Meta LLM (A.I. Chat)",marketplace:"API Marketplace",workflow:"Workflow",repository:"Repository","-- appendix":{type:"separator",title:"\uD83D\uDD17 Appendix"}}},{kind:"MdxPage",name:"index",route:"/docs"},{kind:"Folder",name:"marketplace",route:"/docs/marketplace",children:[{kind:"Meta",data:{concepts:"Market Concepts",purchase:"How to Purchase",application:"Application Creator",seller:"Participate as a Seller",community:"Market Community"}},{kind:"MdxPage",name:"application",route:"/docs/marketplace/application"},{kind:"MdxPage",name:"community",route:"/docs/marketplace/community"},{kind:"MdxPage",name:"concepts",route:"/docs/marketplace/concepts"},{kind:"MdxPage",name:"purchase",route:"/docs/marketplace/purchase"},{kind:"MdxPage",name:"seller",route:"/docs/marketplace/seller"}]},{kind:"Folder",name:"membership",route:"/docs/membership",children:[{kind:"Meta",data:{join:"Membership Joining",account:"Personal Account",enterprise:"Enterprise Accont",seller:"Marketplace Seller"}},{kind:"MdxPage",name:"account",route:"/docs/membership/account"},{kind:"MdxPage",name:"enterprise",route:"/docs/membership/enterprise"},{kind:"MdxPage",name:"join",route:"/docs/membership/join"},{kind:"MdxPage",name:"seller",route:"/docs/membership/seller"}]},{kind:"Folder",name:"repository",route:"/docs/repository",children:[{kind:"Meta",data:{concepts:"Repository Concepts",bucket:"Repository File Tree",release:"Repository Release",settings:"Repository Settings"}},{kind:"MdxPage",name:"bucket",route:"/docs/repository/bucket"},{kind:"MdxPage",name:"concepts",route:"/docs/repository/concepts"},{kind:"MdxPage",name:"release",route:"/docs/repository/release"},{kind:"MdxPage",name:"settings",route:"/docs/repository/settings"}]},{kind:"Folder",name:"workflow",route:"/docs/workflow",children:[{kind:"Meta",data:{concepts:"Workflow Concepts",editor:"Workflow Editor",execution:"Workflow Execution",examples:"Learn from Examples"}},{kind:"MdxPage",name:"concepts",route:"/docs/workflow/concepts"},{kind:"MdxPage",name:"editor",route:"/docs/workflow/editor"},{kind:"MdxPage",name:"examples",route:"/docs/workflow/examples"},{kind:"MdxPage",name:"execution",route:"/docs/workflow/execution"}]}]},{kind:"Folder",name:"tech-specs",route:"/tech-specs",children:[{kind:"Meta",data:{index:"Outline",openapi:"OpenAPI Specification",meta:"Meta LLM (A.I. Chatbot)",marketplace:"API Marketplace",workflow:"Workflow Engine",swl:"SWL Language",appendix:"Appendix"}},{kind:"Folder",name:"appendix",route:"/tech-specs/appendix",children:[{kind:"Meta",data:{api:{title:"⇲ API Documents",href:"/studio-pro/api/",newWindow:!0},swagger:{title:"⇲ Swagger UI",href:"/studio-pro/swagger/",newWindow:!0}}}]},{kind:"MdxPage",name:"index",route:"/tech-specs"},{kind:"Folder",name:"marketplace",route:"/tech-specs/marketplace",children:[{kind:"Meta",data:{preface:"Preface",schema:"Marketplace Schema",price:"Pricing Model",application:"Application Creator",examples:"Example Projects"}},{kind:"MdxPage",name:"application",route:"/tech-specs/marketplace/application"},{kind:"MdxPage",name:"examples",route:"/tech-specs/marketplace/examples"},{kind:"MdxPage",name:"preface",route:"/tech-specs/marketplace/preface"},{kind:"MdxPage",name:"price",route:"/tech-specs/marketplace/price"},{kind:"MdxPage",name:"schema",route:"/tech-specs/marketplace/schema"}]},{kind:"Folder",name:"meta",route:"/tech-specs/meta",children:[{kind:"Meta",data:{preface:"Preface",migrate:"Migration Schema",schema:"LLM Function Schema",websocket:"WebSocket RPC",execution:"Function Call Execution"}},{kind:"MdxPage",name:"execution",route:"/tech-specs/meta/execution"},{kind:"MdxPage",name:"migrate",route:"/tech-specs/meta/migrate"},{kind:"MdxPage",name:"preface",route:"/tech-specs/meta/preface"},{kind:"MdxPage",name:"schema",route:"/tech-specs/meta/schema"},{kind:"MdxPage",name:"websocket",route:"/tech-specs/meta/websocket"}]},{kind:"Folder",name:"openapi",route:"/tech-specs/openapi",children:[{kind:"Meta",data:{preface:"Preface",json:"JSON Schema",document:"Document Schema",plugin:"Plugin Properties",convert:"How to convert"}},{kind:"MdxPage",name:"convert",route:"/tech-specs/openapi/convert"},{kind:"MdxPage",name:"document",route:"/tech-specs/openapi/document"},{kind:"MdxPage",name:"json",route:"/tech-specs/openapi/json"},{kind:"MdxPage",name:"plugin",route:"/tech-specs/openapi/plugin"},{kind:"MdxPage",name:"preface",route:"/tech-specs/openapi/preface"}]},{kind:"Folder",name:"swl",route:"/tech-specs/swl",children:[{kind:"Meta",data:{preface:"Preface"}},{kind:"MdxPage",name:"preface",route:"/tech-specs/swl/preface"}]},{kind:"Folder",name:"workflow",route:"/tech-specs/workflow",children:[{kind:"Meta",data:{preface:"Preface",schema:"Workflow Schema",editor:"Workflow Editor",inspector:"JSON Schema Renderer",backend:"Compiler Backend"}},{kind:"MdxPage",name:"backend",route:"/tech-specs/workflow/backend"},{kind:"MdxPage",name:"editor",route:"/tech-specs/workflow/editor"},{kind:"MdxPage",name:"inspector",route:"/tech-specs/workflow/inspector"},{kind:"MdxPage",name:"preface",route:"/tech-specs/workflow/preface"},{kind:"MdxPage",name:"schema",route:"/tech-specs/workflow/schema"}]}]}],flexsearch:{codeblocks:!0},title:"Preface",headings:d},pageNextRoute:"/tech-specs/meta/preface",nextraLayout:r.ZP,themeConfig:o.Z};t.default=(0,a.j)(h)},2069:function(e,t,n){"use strict";var i=n(5893);n(7294),t.Z={logo:()=>(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)("img",{src:"/studio-pro/favicon/android-chrome-180x180.png",width:32,height:32}),(0,i.jsx)("span",{style:{fontWeight:"bold",fontSize:"1.2rem",paddingLeft:10,paddingRight:10},children:"Wrtn Technologies"}),(0,i.jsx)("span",{children:"Studio Pro Documents"})]}),footer:{text:()=>(0,i.jsxs)("span",{children:["Made by"," ",(0,i.jsx)("a",{href:"https://wrtn.ai",target:"_blank",style:{color:"blue"},children:(0,i.jsx)("u",{children:" Wrtn Technologies "})})]})},docsRepositoryBase:"https://github.com/wrtnio/studio-pro",useNextSeoProps:()=>({defaultTitle:"Studio Documents",titleTemplate:"Studio Documents - %s",additionalLinkTags:[{rel:"apple-touch-icon",sizes:"180x180",href:"/favicon/apple-touch-icon.png"},{rel:"manifest",href:"/favicon/site.webmanifest"},...[16,32].map(e=>({rel:"icon",type:"image/png",sizes:"".concat(e,"x").concat(e),href:"/favicon/favicon-".concat(e,"x").concat(e,".png")}))],additionalMetaTags:[{property:"og:image",content:"https://wrtn.io/wp-content/themes/wrtn-ko/images/ogimage.jpg"},{property:"og:type",content:"website"},{property:"og:title",content:"Wrtn Technologies Studio Pro Documents"},{property:"og:description",content:"Wrtn Technologies Studio Pro Documents"},{property:"og:site_name",content:"Wrtn Technologies Studio Pro Documents"},{property:"og:url",content:"https://wrtn.ai/studio"},{name:"twitter:card",content:"summary"},{name:"twitter:image",content:"https://wrtn.io/wp-content/themes/wrtn-ko/images/ogimage.jpg"},{name:"twitter:title",content:"Wrtn Technologies Studio Pro Documents"},{name:"twitter:description",content:"Wrtn Technologies Studio Pro Documents"}]})}},5789:function(){}},function(e){e.O(0,[5083,7942,9856,2888,9774,179],function(){return e(e.s=1988)}),_N_E=e.O()}]);